# Cultural Chronicles 📚

> Preserving India's Oral and Cultural Heritage Through Digital Storytelling

Cultural Chronicles is an AI-powered Streamlit web application designed to preserve and promote India's diverse cultural heritage through multilingual storytelling. The platform empowers communities to share their folk tales, traditions, and cultural stories in their native languages.

![Cultural Chronicles](https://img.shields.io/badge/Cultural-Chronicles-orange)
![Python](https://img.shields.io/badge/Python-3.11+-blue)
![Streamlit](https://img.shields.io/badge/Streamlit-1.47+-red)
![PostgreSQL](https://img.shields.io/badge/PostgreSQL-Ready-blue)

## 🌟 Features

### 📝 Story Submission
- Interactive form for submitting cultural stories in any Indian language
- Image upload support with automatic optimization
- Metadata collection (region, community, story type)
- AI-powered language detection and classification

### 📚 Story Browsing
- Advanced filtering by language, category, story type, and region
- Sortable content with multiple ordering options
- Pagination for easy navigation through large collections
- Expandable story view with translations

### 🔍 Intelligent Search
- Full-text search across titles, content, and metadata
- Targeted search options (title only, content only, language)
- Enhanced result display with contextual information

### 🤖 AI Features
- Pattern-based language detection for major Indian scripts
- Automatic story categorization (Folk Tale, Legend, Tradition, etc.)
- Smart content processing and metadata extraction

## 🚀 Quick Start

### Prerequisites
- Python 3.11 or higher
- PostgreSQL (optional - SQLite fallback available)

### Installation

1. **Clone the repository**
   ```bash
   git clone https://github.com/your-username/cultural-chronicles.git
   cd cultural-chronicles
   ```

2. **Install dependencies**
   ```bash
   pip install streamlit streamlit-option-menu pandas sqlalchemy psycopg2-binary pillow
   ```

3. **Set up the database** (Optional)
   ```bash
   # For PostgreSQL
   export DATABASE_URL="postgresql://username:password@localhost:5432/cultural_chronicles"
   
   # Or use SQLite (default fallback)
   # No setup required - automatic file creation
   ```

4. **Run the application**
   ```bash
   streamlit run app.py --server.port 5000
   ```

5. **Access the application**
   Open your browser to `http://localhost:5000`

### Sample Data
Load sample cultural stories for testing:
```bash
python sample_data.py
```

## 📁 Project Structure

```
cultural-chronicles/
├── app.py                 # Main application entry point
├── pages/                 # Streamlit page modules
│   ├── submit_story.py    # Story submission interface
│   └── browse_stories.py  # Story browsing and filtering
├── utils/                 # Core utility modules
│   ├── data_manager.py    # Database operations
│   ├── database.py        # Database schema and connection
│   └── image_handler.py   # Image processing
├── models/                # AI and ML processing
│   └── ai_handler.py      # Language detection and classification
├── uploads/               # User uploaded images
├── data/                  # Database files (SQLite)
├── sample_data.py         # Sample data generator
├── dependencies.txt       # Python dependencies reference
├── CONTRIBUTING.md        # Contribution guidelines
├── CHANGELOG.md           # Version history
├── LICENSE               # MIT License
└── README.md             # This file
```

## 🛠️ Technology Stack

### Frontend
- **Streamlit**: Web application framework
- **streamlit-option-menu**: Enhanced navigation components
- **Custom CSS**: Gradient styling and responsive design

### Backend
- **Python**: Core application logic
- **Pandas**: Data manipulation and analysis
- **SQLAlchemy**: Database ORM and abstraction
- **Pillow**: Image processing and optimization

### Database
- **PostgreSQL**: Primary database (production)
- **SQLite**: Fallback database (development)

### AI/ML
- **Pattern-based**: Language detection for Indian scripts
- **Keyword-based**: Story classification system
- **Extensible**: Ready for transformer model integration

## 🌍 Supported Languages

Cultural Chronicles supports major Indian languages through Unicode script detection:

- **Hindi** (Devanagari)
- **Telugu** (Telugu script)
- **Tamil** (Tamil script)
- **Malayalam** (Malayalam script)
- **Kannada** (Kannada script)
- **Gujarati** (Gujarati script)
- **Punjabi** (Gurmukhi script)
- **Bengali** (Bengali script)
- **Odia** (Odia script)
- **English** (Latin script)

## 📊 Database Schema

```sql
CREATE TABLE stories (
    id SERIAL PRIMARY KEY,
    title VARCHAR(255) NOT NULL,
    original_text TEXT NOT NULL,
    translated_text TEXT,
    detected_language VARCHAR(50),
    category VARCHAR(100),
    region VARCHAR(100),
    community VARCHAR(100),
    story_type VARCHAR(50),
    language_hint VARCHAR(50),
    image_path VARCHAR(255),
    timestamp TIMESTAMP DEFAULT NOW()
);
```

## 🎨 UI/UX Design

- **Color Scheme**: Orange gradient theme (#FF6B35 to #F7931E)
- **Typography**: Clear, readable fonts with proper hierarchy
- **Responsive**: Adaptive layout for different screen sizes
- **Accessibility**: Semantic HTML and proper contrast ratios
- **Interactive**: Intuitive forms and navigation

## 🔧 Configuration

### Environment Variables
```bash
# Database Configuration (Optional)
DATABASE_URL=postgresql://username:password@host:port/database
PGHOST=localhost
PGPORT=5432
PGDATABASE=cultural_chronicles
PGUSER=username
PGPASSWORD=password

# Application Configuration
STREAMLIT_HOME=/path/to/app
```

### Streamlit Configuration
Create `.streamlit/config.toml`:
```toml
[server]
headless = true
address = "0.0.0.0"
port = 5000

[theme]
primaryColor = "#FF6B35"
backgroundColor = "#FFFFFF"
secondaryBackgroundColor = "#F0F2F6"
textColor = "#262730"
```

## 🤝 Contributing

We welcome contributions to Cultural Chronicles! Please see our [Contributing Guidelines](CONTRIBUTING.md) for details on:

- Code style and standards
- Development workflow
- Testing requirements
- Cultural sensitivity guidelines

### Quick Contribution Steps
1. Fork the repository
2. Create a feature branch
3. Make your changes with proper documentation
4. Test thoroughly
5. Submit a pull request

## 📄 License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

### Cultural Heritage Responsibility
Users are expected to:
- Respect cultural sensitivities and traditions
- Obtain proper permissions when sharing cultural content
- Attribute cultural content appropriately
- Use the software ethically and responsibly

## 📞 Support

- **Issues**: Report bugs and request features on GitHub Issues
- **Documentation**: Check the project wiki for detailed guides
- **Community**: Join our discussions for help and collaboration

## 🚀 Deployment

### Replit Deployment
The application is optimized for Replit deployment:
1. Import the repository to Replit
2. Install dependencies automatically
3. Configure PostgreSQL database
4. Run with automatic port configuration

### Docker Deployment
```dockerfile
FROM python:3.11-slim
WORKDIR /app
COPY requirements.txt .
RUN pip install -r requirements.txt
COPY . .
EXPOSE 5000
CMD ["streamlit", "run", "app.py", "--server.port", "5000"]
```

## 🔮 Future Roadmap

- **Advanced AI**: Transformer models for better language processing
- **Real-time Translation**: Multi-language content translation
- **Audio Support**: Voice story submission and playback
- **Mobile App**: Native mobile application
- **Community Features**: User profiles and social interaction
- **Export Options**: PDF and ebook generation
- **API Development**: RESTful API for third-party integration

## 🏆 Acknowledgments

- **Swecha Foundation**: For the Summer of AI 2025 initiative
- **Viswam.AI**: For organizing the internship program
- **Cultural Communities**: For preserving and sharing their heritage
- **Open Source Community**: For the amazing tools and libraries

---

**Cultural Chronicles** - *Bridging the past with the future through technology* 🌉